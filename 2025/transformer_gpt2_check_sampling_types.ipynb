{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a35f21a4-3a10-44ad-9bab-2f49baf31ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load a pre-trained model and tokenizer (GPT-2 in this example)\n",
    "model_name = \"gpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f38d8112-e732-447c-bd05-49f5efb72104",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Once upon a time\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "max_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bffec391-56aa-4fd6-b74e-397b350bb043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Greedy Decoding ===\n",
      "Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a\n"
     ]
    }
   ],
   "source": [
    "greedy_output = model.generate(\n",
    "    input_ids, \n",
    "    max_length=max_length, \n",
    "    do_sample=False\n",
    ")\n",
    "print(\"=== Greedy Decoding ===\")\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b50a745-fb35-40cd-86d9-034ef0b88407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top‑k Sampling (k = 50) ===\n",
      "Once upon a time, the story will be a short story, usually with a prologue, with the story moving along slowly, with a narrative in it. However, it could be a long story with the story going through some phases, as each\n"
     ]
    }
   ],
   "source": [
    "top_k = 50\n",
    "top_k_output = model.generate(\n",
    "    input_ids, \n",
    "    max_length=max_length, \n",
    "    do_sample=True, \n",
    "    top_k=top_k\n",
    ")\n",
    "print(\"\\n=== Top‑k Sampling (k = {}) ===\".format(top_k))\n",
    "print(tokenizer.decode(top_k_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62e65215-7d7c-4e0b-9c04-787f0f28ee13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top‑p Sampling (p = 0.9) ===\n",
      "Once upon a time the whole thing, or at least the whole place, of the public life, which it was intended for, did have a distinct place in the heart of this country. It was a state of mind, and in truth it was\n"
     ]
    }
   ],
   "source": [
    "top_p = 0.9\n",
    "top_p_output = model.generate(\n",
    "    input_ids, \n",
    "    max_length=max_length, \n",
    "    do_sample=True, \n",
    "    top_p=top_p\n",
    ")\n",
    "print(\"\\n=== Top‑p Sampling (p = {}) ===\".format(top_p))\n",
    "print(tokenizer.decode(top_p_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "044eabf0-5395-4c3d-bb01-622c5aeb8b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Temperature Sampling (temperature = 0.7) ===\n",
      "Once upon a time, she had been able to take the firstborn.\n",
      "\n",
      "But then, she was gone. She had gone.\n",
      "\n",
      "The boy was gone.\n",
      "\n",
      "One day, one night, in the last days, they had\n"
     ]
    }
   ],
   "source": [
    "temperature = 0.7\n",
    "temperature_output = model.generate(\n",
    "    input_ids, \n",
    "    max_length=max_length, \n",
    "    do_sample=True, \n",
    "    temperature=temperature\n",
    ")\n",
    "print(\"\\n=== Temperature Sampling (temperature = {}) ===\".format(temperature))\n",
    "print(tokenizer.decode(temperature_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff8fe08c-bc1a-468a-aa4d-9c3e2bd2c071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Greedy Decoding ===\n",
      "Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a\n",
      "\n",
      "=== Top‑k Sampling (k = 50) ===\n",
      "Once upon a time, the story will be a short story, usually with a prologue, with the story moving along slowly, with a narrative in it. However, it could be a long story with the story going through some phases, as each\n",
      "\n",
      "=== Top‑p Sampling (p = 0.9) ===\n",
      "Once upon a time the whole thing, or at least the whole place, of the public life, which it was intended for, did have a distinct place in the heart of this country. It was a state of mind, and in truth it was\n",
      "\n",
      "=== Temperature Sampling (temperature = 0.7) ===\n",
      "Once upon a time, she had been able to take the firstborn.\n",
      "\n",
      "But then, she was gone. She had gone.\n",
      "\n",
      "The boy was gone.\n",
      "\n",
      "One day, one night, in the last days, they had\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Greedy Decoding ===\")\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))\n",
    "print(\"\\n=== Top‑k Sampling (k = {}) ===\".format(top_k))\n",
    "print(tokenizer.decode(top_k_output[0], skip_special_tokens=True))\n",
    "print(\"\\n=== Top‑p Sampling (p = {}) ===\".format(top_p))\n",
    "print(tokenizer.decode(top_p_output[0], skip_special_tokens=True))\n",
    "print(\"\\n=== Temperature Sampling (temperature = {}) ===\".format(temperature))\n",
    "print(tokenizer.decode(temperature_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5961f0d-1fd8-4c3d-8942-05fe82b3cacf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
